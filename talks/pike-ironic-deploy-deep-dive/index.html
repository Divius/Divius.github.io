<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Ironic Deploy Deep Dive (Pike Version)</title>
                <meta name="author" content="Dmitry Tantsur (divius.inside@gmail.com)">

		<link rel="stylesheet" href="../reveal.js/css/reveal.css">
		<link rel="stylesheet" href="../reveal.js/css/theme/dtantsur.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="../reveal.js/lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi) ? '../reveal.js/css/print/pdf.css' : '../reveal.js/css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">


<section>
    <h1 class="title">Ironic Deploy Deep Dive</h1>
    <h2>The Pike Release Version</h2>
    <br><br>
    <p><small>Dmitry Tantsur (Principal Software Engineer, Red Hat)</small>
    <br>
    <small>
        <a href="https://dtantsur.github.io/talks/pike-ironic-deploy-deep-dive/">
            dtantsur.github.io/talks/pike-ironic-deploy-deep-dive</a>
    </small></p>
</section>

<section>
    <h1>Agenda</h1>
    <ul>
        <li>Scheduling on bare metal nodes</li>
        <li>Initiating the deployment process</li>
        <li>Ironic Conductor and the deploy interface</li>
        <li>Managing power and boot devices</li>
        <li>Connecting networks and VIFs</li>
        <li>iSCSI-based deploy procedure</li>
    </ul>
    <p><small>Tear down is covered by another deep dive.</small></p>
</section>

<section>

<section>
    <h1 class="title">Scheduling on bare metal</h1>
</section>

<section>
    <h1>Scheduling on bare metal</h1>
    <h2>Exposing resources - before Pike</h2>
    <p>Historically, we've been exposing bare metal resources similar to the
    way virtual resources are exposed:
    <a href="https://github.com/openstack/nova/blob/3284851437e24250d46edba20789a2e5f1f435a0/nova/virt/ironic/driver.py#L261-L325">
        nova/virt/ironic/driver.py</a>.
    </p>
    <p>For example, a node with 16 GiB of RAM and 4 CPUs was represented as a
    hypervisor with 16 GiB of RAM and 4 CPUs.</p>
    <p>When <strong>any</strong> instance is deployed on it, it's reported as
    a hypervisor with 16 GiB RAM and 4 CPUs used.</p>
</section>

<section>
    <h1>Scheduling on bare metal</h1>
    <h2>Exact filters</h2>
    <p>This approach is racy. If a users asks for 2 instances with 2 GiB of RAM
    and one 1 CPU each, the scheduler can try placing both of them on the same
    bare metal node. Only one of the attempts will succeed.</p>
    <ul>
        <li>One mitigation is to use <em>exact scheduling filters</em>.</li>
        <li>Another is to have a lot of retries in the
            <var>RetryFilter</var>. TripleO uses <strong>30</strong>.</li>
    </ul>
</section>

<section>
    <h1>Scheduling on bare metal</h1>
    <h2>Exposing resources - Pike</h2>
    <p>Now every node exposes several <em>resource classes</em> to the
    scheduler:
    <a href="https://github.com/openstack/nova/blob/6c3520ac5ba789dd40d51c0d20a30d0dc44a8c07/nova/virt/ironic/driver.py#L632-L671">
        nova/virt/ironic/driver.py</a>.
    </p>
    <p>This includes traditional memory/disk/CPU resources, as well as
    baremetal-specific <em>custom resource class</em>, fetches from a node's
    <var>resource_class</var> field.</p>
</section>

<section>
    <h1>Scheduling on bare metal</h1>
    <h2>Exposing resources - After Pike</h2>
    <p>At some point in time bare metal nodes will stop expose memory/disk/CPU
    resources to the scheduler completely.</p>
    <p>Flavors targeting bare metal will have to request a custom resource
    class instead of them:
    <a href="https://docs.openstack.org/project-install-guide/baremetal/draft/configure-nova-flavors.html#scheduling-based-on-resource-classes">
        install-guide</a>.
    </p>
</section>

<section>
    <h1>Scheduling on bare metal</h1>
    <h2>Capabilities</h2>
    <p><em>Capabilities</em> allow picking nodes based on non-standard
    properties. Nowadays they are partly replaced by <em>custom resource
    classes</em>, but can still be useful.</p>
    <p>A flavor can have capabilities requested via its <var>extra_specs</var>.
    They will be matched against capabilities as reported by the Ironic Nova
    driver: <a href="https://github.com/openstack/nova/blob/6c3520ac5ba789dd40d51c0d20a30d0dc44a8c07/nova/virt/ironic/driver.py#L286-L299">
        nova/virt/ironic/driver.py</a></p>
</section>

</section>
<section>

<section>
    <h1 class="title">Initiating the deployment</h1>
</section>

<section>
    <h1>Initiating the deployment</h1>
    <h2>High-level overview</h2>
    <p><a href="https://github.com/openstack/nova/blob/6c3520ac5ba789dd40d51c0d20a30d0dc44a8c07/nova/virt/ironic/driver.py#L856-L964">
        nova/virt/ironic/driver.py</a></p>
    <ol>
        <li>Add <var>instance_info</var> to the node</li>
        <li>Add <var>instance_uuid</var> to lock the node</li>
        <li>Validate the final node information</li>
        <li>Plug VIFs and start the firewall</li>
        <li>Build and store a config drive</li>
        <li>Issue a provisioning request</li>
        <li>Wait for the inevitable success</li>
    </ol>
</section>

<section>
    <h1>Initiating the deployment</h1>
    <h2>Instance information</h2>
    <p><a href="https://github.com/openstack/nova/blob/6c3520ac5ba789dd40d51c0d20a30d0dc44a8c07/nova/virt/ironic/patcher.py">
        nova/virt/ironic/patcher.py</a></p>
    <ul>
        <li>Image information: Glance source, disk, swap and ephemeral
            partition sizes</li>
        <li>Nova host ID (used when binding ports)</li>
        <li>Flavor details: VCPUs, memory, disk (will probably go away
            eventually)</li>
        <li>Requested (and matched capabilities)</li>
    </ul>
</section>

<section>
    <h1>Initiating the deployment</h1>
    <h2>Instance UUID</h2>
    <p>The <var>instance_uuid</var> field is used to lock the chosen node.</p>
    <p>Before this point, the node picked by the scheduler can still be used
    by anything else. This is where potential races can happen.</p>
    <p>The <var>instance_uuid</var> field can only be added or removed,
    but it's not possible to replace an existing value.</p>
    <p>So after it's successfully set to an instance UUID, Nova is safe
    to proceed with deploying on it.</p>
</section>

<section>
    <h1>Initiating the deployment</h1>
    <h2>Plugging VIFs</h2>
    <p>Ironic has to know VIF IDs to be able to talk to Neutron.</p>
    <p>Previously, they were passed via <var>extra[vif_port_id]</var>, now
    we have a separate API for that.</p>
    <p>Nova requests every VIF to be plugged:
    <a href="https://github.com/openstack/nova/blob/6c3520ac5ba789dd40d51c0d20a30d0dc44a8c07/nova/virt/ironic/driver.py#L1251-L1264">
        nova/virt/ironic/driver.py</a>. Everything else is handled by
    Ironic itself.</p>
</section>

<section>
    <h1>Initiating the deployment</h1>
    <h2>Provision state change</h2>
    <p>The deployment is initiated by requesting provision state
    <var>active</var> for the node.</p>
    <p>The a looping call is established to wait for a provision state that
    indicates either success (<var>active</var>) or a failure. It also accounts
    for a potential deletion request in the middle of a deployment:
    <a href="https://github.com/openstack/nova/blob/6c3520ac5ba789dd40d51c0d20a30d0dc44a8c07/nova/virt/ironic/driver.py#L401-L428">
        nova/virt/ironic/driver.py</a></p>
</section>

</section>
<section>

<section>
    <h1 class="title">Ironic deployment overview</h1>
</section>

<section>
    <h1>Ironic deployment overview</h1>
    <h2>Preparation</h2>
    <ol>
        <li>Plug VIFs</li>
        <li>Cache images</li>
        <li>Configure boot environment (PXE, iPXE, virtual media)</li>
        <li>Connect the provisioning network to the node</li>
        <li>Boot the ramdisk (IPA)</li>
        <li>Wait for a callback from the ramdisk</li>
    </ol>
</section>

<section>
    <h1>Ironic deployment overview</h1>
    <h2>Deployment - iSCSI method</h2>
    <ol>
        <li>Request IPA to expose the root disk as an iSCSI share</li>
        <li>Mount the resulting iSCSI share to the conductor</li>
        <li>In case of partition images - partition the target
            device</li>
        <li>Flash the instance image to the target device</li>
        <li>Write the config drive, if provided</li>
        <li>In case of partition images and local boot - install the
            bootloader on the target device</li>
        <li>Unmount the iSCSI share</li>
    </ol>
</section>

<section>
    <h1>Ironic deployment overview</h1>
    <h2>Deployment - direct method</h2>
    <ol>
        <li>In case of partition images - request IPA to partition the target
            device</li>
        <li>Request IPA to flash the instance image (fetched from a Swift
            temporary URL or an HTTP location) to the target device</li>
        <li>Request IPA to write the config drive, if provided</li>
        <li>In case of partition images and local boot - request IPA to install
            the bootloader on the target device</li>
    </ol>
</section>

<section>
    <h1>Ironic deployment overview</h1>
    <h2>Finishing</h2>
    <ol>
        <li>Request IPA to power off the machine</li>
        <li>Disconnect the provisioning network and connect tenant
            network(s)</li>
        <li>Set the boot device as requested</li>
        <li>Power on the machine</li>
    </ol>
</section>

</section>
<section>

<section>
    <h1 class="title">Ironic drivers overview</h1>
</section>

<section>
    <h1>Ironic drivers overview</h1>
    <h2>Driver interfaces</h2>
    <p>Most of the deployment actions are done by drivers. The drivers, in turn,
    consist of <em>interfaces</em>, each with a different role in hardware
    management.</p>
</section>

<section>
    <h1>Ironic drivers overview</h1>
    <h2>Power and management</h2>
    <p>The <em>power</em> interface handles powering nodes on and off</p>
    <p>The <em>management</em> interface handles additional vendor-specific
    actions, like getting or setting boot device.</p>
    <p>These drivers are tied to the protocol to access the BMC</p>
    <p>Examples include ipmitool, redfish, ilo.</p>
</section>

<section>
    <h1>Ironic drivers overview</h1>
    <h2>Boot and deploy</h2>
    <p>The <em>boot</em> interface handles how either the deployment ramdisk or
    the final instance get booted on the node. Examples include PXE/iPXE and
    vendor-specific virtual media approaches.</p>
    <p>The <em>deploy</em> interface orchestrates the deployment process,
    including how exactly an image gets transferred to a node. Currently
    supported are iSCSI-based and direct deploy methods.</p>
</section>

<section>
    <h1>Ironic drivers overview</h1>
    <h2>Network</h2>
    <p>The <em>network</em> interface handles how networks are connected to
    and disconnected from a node</p>
    <p>Currently supported are the following implementations:
    <ul>
        <li><em>none</em> networking does nothing, and expects DHCP to be
            configured externally.</li>
        <li><em>flat</em> networking uses Neutron with one flat provision
            network, also serving as a tenant network.</li>
        <li><em>neutron</em> networking also uses Neutron, but it is able to
            talk to switch-specific ML2 drivers to connect/disconnect different
            networks to and from nodes.</li>
    </ul>
</section>

</section>
<section>

<section>
    <h1 class="title">Preparation for deployment</h1>
</section>

</section>

			</div>
		</div>

		<script src="../reveal.js/lib/js/head.min.js"></script>
		<script src="../reveal.js/js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				dependencies: [
					{ src: '../reveal.js/plugin/markdown/marked.js' },
					{ src: '../reveal.js/plugin/markdown/markdown.js' },
					{ src: '../reveal.js/plugin/notes/notes.js', async: true },
					{ src: '../reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
